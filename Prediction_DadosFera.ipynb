{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1QPlXYiCTNzBVitJZFrLs-iiteQ22pk-a",
      "authorship_tag": "ABX9TyMjWC2GKOnEXeaqpIY4z+hi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CeLo93/ML_analise_preditiva_de_fraudes_e_marketing/blob/modificao_generatorData_1.1/Prediction_DadosFera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jhfiv3eup1Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CASE PROJETO**"
      ],
      "metadata": {
        "id": "l6yXu5VyiMMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESUMO:\n",
        "\n",
        "O projeto é uma simulação vívida de como os dados em tempo real podem ser gerados e enviados para um fluxo Kinesis Data Stream na AWS. Esse fluxo é apenas o começo de um processo mais amplo, que pode envolver diversas etapas de processamento e análise.\n",
        "\n",
        "* Geração de Dados em Tempo Real: O código utiliza a biblioteca Faker para criar transações fictícias, como transações de pagamentos, compras etc. Esses dados simulados representam informações que seriam geradas por sistemas reais em tempo real.\n",
        "\n",
        "* Envio para Kinesis Data Streams: As transações fictícias são formatadas e enviadas para um fluxo Kinesis Data Stream. Isso espelha como os dados em tempo real seriam injetados em um fluxo de dados, prontos para serem processados.\n",
        "\n",
        "* Kinesis Data Firehose: Embora não esteja presente no código atual, normalmente, os dados de um fluxo Kinesis são direcionados para o Kinesis Data Firehose. Essa etapa permite transformações e envio simplificado para diversos destinos, como o Amazon S3.\n",
        "\n",
        "* Armazenamento em Amazon S3: O fluxo Kinesis Data Firehose, que segue o fluxo Kinesis, pode ser configurado para armazenar os dados processados no Amazon S3. Isso resulta em um repositório centralizado e escalável para armazenamento de dados brutos.\n",
        "\n",
        "* Extração de Dados para Modelos de ML e Análises: Com os dados armazenados no Amazon S3, é possível extrair, processar e analisar os dados para diversos fins, incluindo treinamento de modelos de aprendizado de máquina, análise de tendências, geração de relatórios e muito mais.\n",
        "\n",
        "* Iteração e Otimização: Uma vez que os dados estão disponíveis em um ambiente de armazenamento durável como o Amazon S3, é possível iterar, otimizar e evoluir os processos de análise, modelagem e visualização de acordo com as necessidades em constante mudança.\n",
        "\n",
        "Em resumo, o projeto é uma representação inicial de como dados simulados em tempo real podem ser injetados em um fluxo Kinesis Data Stream, desencadeando uma série de ações que culminam no armazenamento dos dados no Amazon S3 e na subsequente análise e processamento desses dados. Esse é o ponto de partida para a construção de soluções mais robustas e complexas de processamento de dados em tempo real na AWS, baseada na arquitetura proposta."
      ],
      "metadata": {
        "id": "hRPfDal3zvAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EyepbkEGp0S8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FLUXOGRAMA GERAL\n",
        "      1. Aplicativo Gera Dados\n",
        "      |\n",
        "      v\n",
        "    2. Kinesis Stream\n",
        "      |\n",
        "      v\n",
        "    3. Firehose\n",
        "      |-------------> 4. Redis?\n",
        "      v             \n",
        "    4. Amazon S3\n",
        "      |\n",
        "      v\n",
        "    5. Amazon Fraud Detector\n",
        "      |\n",
        "      |--- [Se Escolher Usar o Amazon Fraud Detector]\n",
        "      |     |\n",
        "      |     v\n",
        "      |   Treinamento de Modelo (Amazon Fraud Detector)\n",
        "      |     |\n",
        "      |     v\n",
        "      |   Avaliação e Otimização do Modelo (Amazon Fraud Detector)\n",
        "      |     |\n",
        "      |     v\n",
        "      |   Implantação do Modelo (Amazon Fraud Detector)\n",
        "      |     |\n",
        "      |     v\n",
        "      |   Detecção de Fraudes em Tempo Real (Amazon Fraud Detector)\n",
        "      |\n",
        "      |--- [Se Escolher Modelo Próprio]\n",
        "            |\n",
        "            v\n",
        "          Treinamento de Modelo Personalizado\n",
        "            |\n",
        "            v\n",
        "          Avaliação e Otimização do Modelo\n",
        "            |\n",
        "            v\n",
        "          Implantação do Modelo (integrado à infraestrutura do aplicativo. Isso pode incluir a criação de APIs ou endpoints que permitam que o aplicativo envie transações para o modelo e receba as previsões de detecção de fraude)\n",
        "            |\n",
        "            v\n",
        "          Detecção de Fraudes em Tempo Real\n"
      ],
      "metadata": {
        "id": "6TDZiT1QcH81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##  **1. Scripts Geradores do Case**\n",
        "\n"
      ],
      "metadata": {
        "id": "buBvbYnym7rr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. ☁ Gerando Dados de alimentação colab-AWS (exemplo)"
      ],
      "metadata": {
        "id": "0r73E_bynF5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basicamente ele simula os dados em tempo real que são enviado para o Kinesis Data Streams criado. À partir disso, seguirá o fluxo para o firehouse e depois para o armazenamento S3"
      ],
      "metadata": {
        "id": "objjKnHVnOha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala o boto3\n",
        "!pip install boto3\n",
        "!pip install faker"
      ],
      "metadata": {
        "id": "PtQOKHdUWY2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flQRjAYnWFMI"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import random\n",
        "import time\n",
        "from faker import Faker\n",
        "import csv\n",
        "\n",
        "# Configuração das credenciais de acesso (substitua pelas suas credenciais)\n",
        "AWS_ACCESS_KEY_ID = 'YOUR_ACCESS_KEY'\n",
        "AWS_SECRET_ACCESS_KEY = 'YOUR_SECRET_KEY'\n",
        "REGION_NAME = 'sa-east-1'\n",
        "\n",
        "# Nome do stream Kinesis criado\n",
        "stream_name = 'xxx-stream'\n",
        "\n",
        "# Inicialização do cliente Kinesis\n",
        "kinesis_client = boto3.client('kinesis', region_name=REGION_NAME,\n",
        "                              aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "                              aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
        "\n",
        "# Inicialização da biblioteca Faker para geração de dados fictícios\n",
        "fake = Faker()\n",
        "\n",
        "# Lista de cidades e estados do Brasil para o exemplo\n",
        "cidades_estados = [\n",
        "    (\"São Paulo\", \"SP\"),\n",
        "    (\"Rio de Janeiro\", \"RJ\"),\n",
        "    (\"Belo Horizonte\", \"MG\"),\n",
        "    (\"Salvador\", \"BA\"),\n",
        "    (\"Curitiba\", \"PR\"),\n",
        "    (\"Fortaleza\", \"CE\"),\n",
        "    (\"Porto Alegre\", \"RS\"),\n",
        "    (\"Recife\", \"PE\"),\n",
        "    (\"Brasília\", \"DF\"),\n",
        "    (\"Goiânia\", \"GO\"),\n",
        "    (\"Belo Horizonte\", \"MG\"),\n",
        "    (\"Manaus\", \"AM\"),\n",
        "    (\"Belém\", \"PA\"),\n",
        "    (\"Campinas\", \"SP\"),\n",
        "    (\"São Luís\", \"MA\"),\n",
        "    (\"São Gonçalo\", \"RJ\"),\n",
        "    (\"Maceió\", \"AL\"),\n",
        "    (\"Duque de Caxias\", \"RJ\"),\n",
        "    (\"Natal\", \"RN\"),\n",
        "    (\"Montes Claros\", \"MG\"),\n",
        "    (\"Campo Grande\", \"MS\"),\n",
        "    (\"Teresina\", \"PI\"),\n",
        "    (\"Osasco\", \"SP\"),\n",
        "    (\"Cuiabá\", \"MT\"),\n",
        "    (\"Aracaju\", \"SE\"),\n",
        "    (\"Feira de Santana\", \"BA\"),\n",
        "    (\"Santarém\", \"PA\"),\n",
        "    (\"Londrina\", \"PR\"),\n",
        "    (\"Juiz de Fora\", \"MG\"),\n",
        "]\n",
        "\n",
        "# Função para gerar uma transação fictícia aleatória\n",
        "def generate_random_transaction():\n",
        "    # Gera um nome completo fictício\n",
        "    nome_completo = fake.name()\n",
        "    # Escolhe aleatoriamente uma cidade e estado da lista de cidades_estados\n",
        "    cidade, estado = random.choice(cidades_estados)\n",
        "    # Gera um saldo atual fictício entre 100 e 50000\n",
        "    saldo_atual = round(random.uniform(100, 50000), 2)\n",
        "\n",
        "    # Cria um dicionário representando a transação\n",
        "    transaction = {\n",
        "        'customer_id': fake.uuid4(),  # Gera um ID de cliente fictício\n",
        "        'nome_completo': nome_completo,\n",
        "        'cidade': cidade,\n",
        "        'estado': estado,\n",
        "        'data': fake.date_between(start_date='-1y', end_date='today').strftime('%Y-%m-%d'),\n",
        "        'transacao': fake.random_element(elements=('Pix Receber','Pix Enviar','TED Receber','TED Enviar','Compra Cartão','Venda Maquininha')),  # Escolhe aleatoriamente um tipo de transação\n",
        "        'horario': fake.time(),\n",
        "        'valor': round(random.uniform(10, 20000), 2),  # Gera um valor fictício entre 10 e 20000\n",
        "        'saldo_atual': saldo_atual\n",
        "    }\n",
        "    return transaction\n",
        "\n",
        "# Loop principal para gerar e enviar transações continuamente\n",
        "while True:\n",
        "    # Gera uma transação fictícia\n",
        "    transaction = generate_random_transaction()\n",
        "\n",
        "    # Formata os dados da transação como uma linha CSV\n",
        "    csv_data = [\n",
        "        transaction['customer_id'],\n",
        "        transaction['nome_completo'],\n",
        "        transaction['cidade'],\n",
        "        transaction['estado'],\n",
        "        transaction['data'],\n",
        "        transaction['transacao'],\n",
        "        transaction['horario'],\n",
        "        str(transaction['valor']),  # Converte o valor para string\n",
        "        str(transaction['saldo_atual'])  # Converte o saldo atual para string\n",
        "    ]\n",
        "    csv_row = ','.join(csv_data) + '\\n'\n",
        "\n",
        "    # Envia os dados para o stream Kinesis, incluindo a chave de particionamento\n",
        "    response = kinesis_client.put_record(\n",
        "        StreamName=stream_name,\n",
        "        Data=csv_row.encode('utf-8'),  # Codifica a linha CSV como bytes\n",
        "        PartitionKey=transaction['estado']  # Define a chave de particionamento como estado\n",
        "    )\n",
        "\n",
        "    # Exibe uma mensagem indicando que a transação foi enviada para o stream\n",
        "    print(f\"Enviado para Kinesis: {csv_row}\")\n",
        "\n",
        "    # Introduz uma pausa aleatória antes de gerar e enviar a próxima transação\n",
        "    time.sleep(random.uniform(0.5, 2.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.1. 🔑**Comentário sobre a chave de particionamento:**\n",
        "\n",
        "É importante salientar que o Amazon Kinesis é um serviço da AWS que permite a ingestão, processamento e análise de dados em tempo real. Ele opera por meio de streams, que são fluxos contínuos de dados que podem ser processados por várias aplicações simultaneamente.\n",
        "\n",
        "A chave de particionamento desempenha um papel crucial em um stream do Amazon Kinesis. Ela determina como os registros são distribuídos entre as partições do stream e, no contexto deste exemplo, como eles serão organizados para serem enviados ao Amazon S3 no final do ciclo de processamento, levando em consideração a estrutura de pastas dos dados. Cada registro em um stream do Kinesis precisa estar associado a uma chave de particionamento, que é usada pelo Kinesis para decidir em qual partição esse registro será armazenado.\n",
        "\n",
        "No código fornecido, a chave de particionamento foi definida como `transaction['estado']`, utilizando o estado (por exemplo, MG, SP, RJ) gerado ficticiamente como base para a chave. Isso implica que todos os registros com o mesmo ID de cliente serão direcionados para a mesma partição no stream. Essa abordagem pode ser benéfica em cenários em que desejamos agrupar registros relacionados em uma única partição, seja para otimização do processamento ou para preservar a ordem de processamento. Optar por uma chave de particionamento que abrange um maior conjunto de registros, como o estado ou a cidade, pode contribuir para uma distribuição mais equitativa da carga entre as partições do stream Kinesis e, potencialmente, resultar em uma utilização mais eficiente dos recursos, quando comparado ao uso de um campo exclusivo, como um ID único, como chave de particionamento. No caso do uso de um campo exclusivo, como um ID, cada registro é direcionado a uma partição específica com base no valor único do ID, o que pode resultar em desequilíbrio de carga, onde algumas partições recebem mais registros do que outras, impactando o desempenho e escalabilidade do stream.\n",
        "\n",
        "Por outro lado, ao optar por um campo mais abrangente, como o estado ou cidade, como chave de particionamento, os registros serão distribuídos entre as partições de acordo com esses valores mais genéricos. Essa abordagem ajuda a evitar o desequilíbrio de carga, assegurando uma distribuição mais uniforme dos registros, o que pode resultar em um uso mais eficaz dos recursos do stream e, consequentemente, um desempenho aprimorado.\n",
        "\n",
        "No entanto, é importante notar que a escolha da chave de particionamento pode ter implicações no dimensionamento e desempenho do stream Kinesis, dependendo do volume de dados e padrões de acesso. Portanto, é fundamental selecionar uma chave de particionamento que atenda às necessidades específicas do caso. Em cenários em que a granularidade dos dados é crucial e é necessário preservar a ordem de processamento para registros relacionados, como todas as transações de um único cliente, pode ser mais apropriado optar por um campo exclusivo como chave de particionamento, mesmo que isso resulte em um desequilíbrio de carga.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eAAYHc4snR6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.  Gerando dados pelo colab para o lambda (exemplo)"
      ],
      "metadata": {
        "id": "ZrBkY0nBDzGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import random\n",
        "import time\n",
        "from faker import Faker\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "def generate_random_transaction():\n",
        "    transaction = [\n",
        "        fake.uuid4(),\n",
        "        fake.city(),\n",
        "        fake.date_between(start_date='-5y', end_date='today').strftime('%Y-%m-%d'),\n",
        "        fake.random_element(elements=('Compra', 'Venda', 'Transferência')),\n",
        "        fake.time(),\n",
        "        round(random.uniform(10, 10000), 2)\n",
        "    ]\n",
        "    return transaction\n",
        "\n",
        "# URL do seu AWS Lambda API Gateway\n",
        "url = 'https://53tm7m3532.execute-api.sa-east-1.amazonaws.com/default/transmissorData'  # Substitua pela URL real do seu API Gateway\n",
        "headers = {'Content-Type': 'text/csv'}\n",
        "\n",
        "while True:\n",
        "    transaction = generate_random_transaction()\n",
        "\n",
        "    csv_data = ','.join(map(str, transaction))\n",
        "    csv_io = StringIO()\n",
        "    csv_io.write(csv_data)\n",
        "    csv_io.seek(0)\n",
        "\n",
        "    response = requests.post(url, data=csv_io, headers=headers)\n",
        "    print(f\"Enviado para Lambda: {response.text}\")\n",
        "\n",
        "    time.sleep(1)  # Espera 1 segundo antes de gerar e enviar o próximo conjunto de dados\n"
      ],
      "metadata": {
        "id": "6zYol84TWZW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. 🔢 Gerador simulado dos dados - ***Dados utilizados no modelo ML***🔢"
      ],
      "metadata": {
        "id": "YjM-zVUbrVqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "id": "m2aFQjcLzY8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "import time\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Lista de nomes com nome completo, sexo e número de conta\n",
        "nomes_sexo_conta = [\n",
        "    (\"João da Silva\", \"M\", \"17251-9\"),\n",
        "    (\"Maria dos Santos\", \"F\", \"21587-3\"),\n",
        "    (\"Pedro Almeida Filho\", \"M\", \"36428-6\"),\n",
        "    (\"Ana Pereira de Oliveira\", \"F\", \"50319-0\"),\n",
        "    (\"Carlos Souza Júnior\", \"M\", \"65004-5\"),\n",
        "    (\"Lúcia Oliveira Costa\", \"F\", \"74896-2\"),\n",
        "    (\"Fernando Carvalho Neto\", \"M\", \"80750-8\"),\n",
        "    (\"Mariana Castro Ribeiro\", \"F\", \"93216-1\"),\n",
        "    (\"Rafael Mendes Freitas\", \"M\", \"06891-7\"),\n",
        "    (\"Camila Rodrigues Figueiredo\", \"F\", \"10152-2\"),\n",
        "    (\"André Lima Cunha\", \"M\", \"22645-3\"),\n",
        "    (\"Luísa Costa Gomes\", \"F\", \"31075-4\"),\n",
        "    (\"Amanda Oliveira Lima\", \"F\", \"43910-8\"),\n",
        "    (\"Bruno Alves Martins\", \"M\", \"58243-9\"),\n",
        "    (\"Carolina Barbosa Andrade\", \"F\", \"64519-5\"),\n",
        "    (\"Diego Ferreira Nunes\", \"M\", \"77061-2\"),\n",
        "    (\"Elisa Rocha Ferreira\", \"F\", \"82653-6\"),\n",
        "    (\"Gabriel Lima Santos\", \"M\", \"95670-7\"),\n",
        "    (\"Helena Fernandes Barbosa\", \"F\", \"04289-1\"),\n",
        "    (\"Igor Barbosa Mendes\", \"M\", \"19835-4\"),\n",
        "    (\"Juliana Santos Rodrigues\", \"F\", \"32680-5\"),\n",
        "    (\"Kaique Souza Almeida\", \"M\", \"43910-8\"),\n",
        "    (\"Laura Rodrigues Nunes\", \"F\", \"57326-0\"),\n",
        "    (\"Mateus Almeida Cardoso\", \"M\", \"64519-5\"),\n",
        "    (\"Natália Pereira Costa\", \"F\", \"76284-3\"),\n",
        "    (\"Otávio Carvalho Santos\", \"M\", \"95831-1\"),\n",
        "    (\"Paula Nobre Souza\", \"F\", \"07348-7\"),\n",
        "    (\"Ricardo Mendes Oliveira\", \"M\", \"13159-0\"),\n",
        "    (\"Sofia Costa Alves\", \"F\", \"27694-9\"),\n",
        "    (\"Thiago Oliveira Silva\", \"M\", \"47921-4\"),\n",
        "    (\"Valentina Martins Ferreira\", \"F\", \"63982-3\")\n",
        "]\n",
        "\n",
        "# Lista de cidades e estados do Brasil para o exemplo\n",
        "cidades_estados = [\n",
        "    (\"São Paulo\", \"SP\"),\n",
        "    (\"Rio de Janeiro\", \"RJ\"),\n",
        "    (\"Belo Horizonte\", \"MG\"),\n",
        "    (\"Salvador\", \"BA\"),\n",
        "    (\"Curitiba\", \"PR\"),\n",
        "    (\"Fortaleza\", \"CE\"),\n",
        "    (\"Porto Alegre\", \"RS\"),\n",
        "    (\"Recife\", \"PE\"),\n",
        "    (\"Brasília\", \"DF\"),\n",
        "    (\"Goiânia\", \"GO\"),\n",
        "    (\"Belo Horizonte\", \"MG\"),\n",
        "    (\"Manaus\", \"AM\"),\n",
        "    (\"Belém\", \"PA\"),\n",
        "    (\"Campinas\", \"SP\"),\n",
        "    (\"São Luís\", \"MA\"),\n",
        "    (\"São Gonçalo\", \"RJ\"),\n",
        "    (\"Maceió\", \"AL\"),\n",
        "    (\"Duque de Caxias\", \"RJ\"),\n",
        "    (\"Natal\", \"RN\"),\n",
        "    (\"Montes Claros\", \"MG\"),\n",
        "    (\"Campo Grande\", \"MS\"),\n",
        "    (\"Teresina\", \"PI\"),\n",
        "    (\"Osasco\", \"SP\"),\n",
        "    (\"Cuiabá\", \"MT\"),\n",
        "    (\"Aracaju\", \"SE\"),\n",
        "    (\"Feira de Santana\", \"BA\"),\n",
        "    (\"Santarém\", \"PA\"),\n",
        "    (\"Londrina\", \"PR\"),\n",
        "    (\"Juiz de Fora\", \"MG\"),\n",
        "]\n",
        "\n",
        "\n",
        "# Nomes das colunas\n",
        "column_names = ['customer_id', 'nome_completo', 'sexo', 'cidade', 'estado',\n",
        "                'data', 'horario', 'transacao', 'valor_transacao', 'saldo_atual',\n",
        "                'tipo_conta', 'numero_conta', 'numero_referencia', 'codigo_transacao',\n",
        "                'categoria_transacao', 'localizacao_geografica', 'metodo_pagamento',\n",
        "                'valor_taxa', 'descricao_transacao', 'status_transacao',\n",
        "                'numero_parcelas', 'data_vencimento', 'informacoes_beneficiario_remetente',\n",
        "                'identificador_unico_transacao']\n",
        "\n",
        "# Dicionário para armazenar os saldos de cada pessoa\n",
        "saldos_pessoas = {nome: {'saldo_atual': 0.0} for nome, _, _ in nomes_sexo_conta}\n",
        "\n",
        "# Lista para armazenar as transações geradas\n",
        "transactions = []\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# Gera descrições de transações com base no tipo de transação\n",
        "def generate_transaction_description(transacao):\n",
        "    if transacao == 'Pix Receber':\n",
        "        return fake.random_element(elements=('Venda de produtos', 'Serviços prestados', 'Recebimento por venda', 'Outros'))\n",
        "    elif transacao == 'Pix Enviar':\n",
        "        return fake.random_element(elements=('Compra de roupas', 'Compra de supermercado', 'Compra no restaurante',\n",
        "                                             'Compra de eletrônicos', 'Contas pessoais', 'Outros', 'Compra saúde'))\n",
        "    elif transacao == 'TED Receber':\n",
        "        return fake.random_element(elements=('Venda de produtos', 'Serviços prestados', 'Recebimento por venda', 'Outros', 'Outros'))\n",
        "    elif transacao == 'TED Enviar':\n",
        "        return fake.random_element(elements=('Compra de roupas', 'Compra de supermercado', 'Compra no restaurante',\n",
        "                                             'Compra de eletrônicos', 'Contas pessoais', 'Outros', 'Compra saúde'))\n",
        "    elif transacao == 'Compra Cartão':\n",
        "        return fake.random_element(elements=('Compra de roupas', 'Compra de supermercado', 'Compra no restaurante',\n",
        "                                             'Compra de eletrônicos', 'Contas pessoais', 'Outros', 'Compra saúde', 'Outros'))\n",
        "    elif transacao == 'Venda Maquininha':\n",
        "        return fake.random_element(elements=('Venda de produtos', 'Serviços prestados', 'Recebimento por venda', 'Outros', 'Outros'))\n",
        "    else:\n",
        "        return \"Descrição não identificada\"\n",
        "\n",
        "\n",
        "# Gera uma transação aleatória com base nos dados fornecidos\n",
        "def generate_random_transaction(nome_sexo_conta, cidade_estado):\n",
        "    nome_completo, sexo, numero_conta = nome_sexo_conta\n",
        "    cidade, estado = cidade_estado\n",
        "    latitude = str(fake.latitude())\n",
        "    longitude = str(fake.longitude())\n",
        "\n",
        "    transacao = fake.random_element(elements=('Pix Receber', 'Pix Enviar', 'TED Receber', 'TED Enviar', 'Compra Cartão', 'Venda Maquininha'))\n",
        "\n",
        "    if transacao in ['Pix Receber', 'TED Receber']:\n",
        "        numero_parcelas = 1\n",
        "        valor_taxa = 0\n",
        "        valor_transacao = round(random.uniform(1, 2000), 2)\n",
        "    elif transacao in ['Pix Enviar', 'TED Enviar']:\n",
        "        numero_parcelas = 1\n",
        "        valor_taxa = round(random.uniform(1, 10), 2)\n",
        "        valor_transacao = round(random.uniform(1, 2000), 2)\n",
        "    else:\n",
        "        numero_parcelas = random.randint(1, 10)\n",
        "        valor_taxa = round(random.uniform(1, 10), 2)\n",
        "        valor_transacao = round(random.uniform(1, 2000), 2)\n",
        "\n",
        "    saldo_atual = saldos_pessoas[nome_completo]['saldo_atual']\n",
        "\n",
        "    if transacao in ['Pix Receber', 'TED Receber', 'Venda Maquininha']:\n",
        "        saldo_atual += valor_transacao\n",
        "    elif transacao in ['Pix Enviar', 'TED Enviar', 'Compra Cartão']:\n",
        "        saldo_atual -= valor_transacao\n",
        "\n",
        "    # Arredondar o saldo atual para duas casas decimais\n",
        "    saldo_atual = round(saldo_atual, 2)\n",
        "\n",
        "    descricao_transacao = generate_transaction_description(transacao)\n",
        "\n",
        "    # Chance de 0.5% de gerar uma transação anômala com valor entre 4000 e 15000\n",
        "    if random.random() < 0.015:\n",
        "        valor_transacao = round(random.uniform(4000, 15000), 2)\n",
        "        saldo_atual += valor_transacao  # Atualiza o saldo após a transação anômala\n",
        "        saldo_atual = round(saldo_atual, 2)  # Arredondar o saldo após a transação anômala\n",
        "        descricao_transacao = \"Desconhecido\"  # Altera a descrição para \"Desconhecido\"\n",
        "\n",
        "\n",
        "    transaction = [\n",
        "        fake.uuid4(),\n",
        "        nome_completo,\n",
        "        sexo,\n",
        "        cidade,\n",
        "        estado,\n",
        "        fake.date_between(start_date='-1y', end_date='today').strftime('%Y-%m-%d'),\n",
        "        fake.time(),\n",
        "        transacao,\n",
        "        valor_transacao,\n",
        "        saldo_atual,\n",
        "        fake.random_element(elements=('Conta Corrente', 'Conta Poupança', 'Investimento')),\n",
        "        numero_conta,\n",
        "        fake.uuid4(),\n",
        "        fake.random_element(elements=('001', '002', '003', '004', '005')),\n",
        "        fake.random_element(elements=('Alimentação', 'Vestuário', 'Viagens', 'Eletrônicos',\n",
        "                                      'Shopping', 'Esporte','Informática', 'Outros')),\n",
        "        latitude + ', ' + longitude,\n",
        "        fake.random_element(elements=('Cartão de Crédito', 'Cartão de Débito', 'Dinheiro')),\n",
        "        valor_taxa,\n",
        "        descricao_transacao,\n",
        "        fake.random_element(elements=('Concluída', 'Pendente', 'Recusada')),\n",
        "        numero_parcelas,\n",
        "        fake.date_between(start_date='-1y', end_date='today').strftime('%Y-%m-%d'),\n",
        "        fake.name(),\n",
        "        fake.uuid4()\n",
        "    ]\n",
        "    return transaction\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# Simulando envio de dados e salvando em uma lista\n",
        "num_saida_dados = 300  # Defina o número de saídas de dados desejado\n",
        "for _ in range(num_saida_dados):\n",
        "    # Seleciona nomes, sexo e número de conta aleatoriamente\n",
        "    nome_sexo_conta = random.choice(nomes_sexo_conta)\n",
        "    nome_completo, sexo, numero_conta = nome_sexo_conta\n",
        "\n",
        "    # Seleciona uma cidade e estado aleatoriamente\n",
        "    cidade_estado = random.choice(cidades_estados)\n",
        "\n",
        "    # Gera uma transação aleatória\n",
        "    transaction = generate_random_transaction(nome_sexo_conta, cidade_estado)\n",
        "\n",
        "    # Atualiza o saldo da pessoa com base na transação gerada\n",
        "    saldos_pessoas[nome_completo]['saldo_atual'] = transaction[9]\n",
        "\n",
        "    # Adiciona a transação à lista de transações\n",
        "    transactions.append(transaction)\n",
        "\n",
        "    # Imprime a transação gerada\n",
        "    print(f\"Gerado: {transaction}\")\n",
        "\n",
        "    # Introduz uma pausa aleatória para simular o envio de dados\n",
        "    time.sleep(random.uniform(0.0001, 0.0002))\n",
        "\n",
        "# Salvar os dados em um arquivo CSV\n",
        "with open('/content/dados.csv', 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerow(column_names)\n",
        "    csv_writer.writerows(transactions)\n",
        "\n",
        "print(\"Dados salvos em 'dados.csv'\")"
      ],
      "metadata": {
        "id": "qr19vu_vrcc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🤖 **2. MACHINE LEARNING**\n",
        "\n"
      ],
      "metadata": {
        "id": "o81icnDgiqKi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XF9tuOvsiuo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Importando Dados S3 (exemplo)"
      ],
      "metadata": {
        "id": "0kPxX5oBiyo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sobre o código S3**\n",
        "\n",
        "*Configuramos as credenciais de acesso, usando a biblioteca boto3 para baixar um arquivo CSV do Amazon S3, carregamos esse arquivo em um DataFrame pandas e, finalmente, exibimos uma amostra das primeiras linhas dos dados. As credenciais são um exemplo de como seria, apenas. Já as excluí.*"
      ],
      "metadata": {
        "id": "jsrlxp68lA7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LCDcgkSEi7er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração das credenciais de acesso (substituir pelas credenciais, neste caso criei estas mas já as excluí.\n",
        "# Mas, facilmente podem ser criadas no IAM)\n",
        "AWS_ACCESS_KEY_ID = 'AKIARPH6FDHBM4SAVQJF'\n",
        "AWS_SECRET_ACCESS_KEY = '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'\n",
        "REGION_NAME = 'sa-east-1'\n",
        "\n",
        "# Importa a biblioteca boto3 que fornece uma interface para interagir com os serviços da AWS.\n",
        "import boto3\n",
        "\n",
        "# Crie uma instância do cliente S3, passando as credenciais para autenticação.\n",
        "s3 = boto3.client('s3', aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key,\n",
        "                  aws_session_token=aws_session_token)\n",
        "\n",
        "# Nome do bucket (repositório no S3) e caminho para o arquivo CSV a ser baixado.\n",
        "bucket_name = 'NOME_DO_BUCKET'\n",
        "file_key = 'CAMINHO_PARA_O_ARQUIVO/dados.csv'\n",
        "\n",
        "# Baixe o arquivo CSV do S3 para o diretório '/content/dados.csv'.\n",
        "s3.download_file(bucket_name, file_key, '/content/dados.csv')\n",
        "\n",
        "# Importa a biblioteca pandas para manipulação de dados.\n",
        "import pandas as pd\n",
        "\n",
        "# Carregue o arquivo CSV em um DataFrame, criando uma estrutura tabular com os dados.\n",
        "data = pd.read_csv('/content/dados.csv')\n",
        "\n",
        "# Exiba as primeiras linhas do DataFrame para visualização.\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "ie10HlARkZ8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Desenvolvimento Dos Modelos de Machine Learning"
      ],
      "metadata": {
        "id": "Px3sYnkWw1LG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1. 👮 Detecção De Fraude - Amazon Fraud **Detector**"
      ],
      "metadata": {
        "id": "_cxMalQvYECI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considerando a estrutura que estamos desenvolvendo para o nosso aplicativo, a avaliação do Amazon Fraud Detector apresenta-se como uma escolha estratégica e eficaz. Este serviço, oferecido pela AWS, é especialmente projetado para a detecção de fraudes, incorporando algoritmos avançados e técnicas de machine learning, o que poderia agregar significativamente ao nosso projeto.\n",
        "\n",
        "Há diversos motivos pelos quais o Amazon Fraud Detector se destaca como uma opção viável:\n",
        "\n",
        "* Usabilidade Intuitiva: A plataforma demonstra uma interface amigável e intuitiva, tornando-a acessível mesmo para profissionais com conhecimento intermediário em machine learning. Isso agiliza a criação de modelos e a configuração de regras de detecção.\n",
        "\n",
        "* Modelos Pré-Treinados: A disponibilidade de modelos pré-treinados é uma vantagem notável. Isso nos permite economizar tempo e recursos, aproveitando a expertise já incorporada nesses modelos e adaptando-os às nossas necessidades específicas.\n",
        "\n",
        "* Integração com o Ecossistema AWS: O Amazon Fraud Detector se integra perfeitamente aos dados que já temos armazenados no Amazon S3. Essa sinergia facilita o processo de implementação e uso dos recursos do serviço.\n",
        "\n",
        "* Personalização Ajustável: Mesmo com modelos pré-existentes, o Amazon Fraud Detector permite uma personalização adequada, permitindo que adaptemos as regras e modelos conforme nossa estratégia e contexto de negócios.\n",
        "\n",
        "* Escalabilidade: Dada a natureza do nosso aplicativo, que envolve grande volume de transações em tempo real, o serviço é escalável e capaz de lidar com demandas crescentes de forma eficiente.\n",
        "\n",
        "* Monitoramento Contínuo e Melhoria: Uma característica notável é a capacidade de monitorar o desempenho do modelo ao longo do tempo. Isso nos possibilita ajustar e otimizar conforme adquirimos mais dados e insights.\n",
        "\n",
        "* Centralização de Gerenciamento: A presença de um painel centralizado de gerenciamento oferece visibilidade completa das operações, permitindo um acompanhamento abrangente do desempenho dos modelos e regras.\n",
        "\n",
        "Assim sendo, a avaliação do Amazon Fraud Detector está alinhada ao nosso objetivo de alcançar eficiência, eficácia e integridade na prevenção de fraudes em nosso aplicativo. A adoção desse serviço pode resultar em economia de tempo, recursos e, sobretudo, contribuir para a proteção dos nossos usuários e a confiança na nossa plataforma. Caso nosso cliente optasse por não usar o Amazon Fraud Detector, estaríamos preparados para desenvolver um modelo interno. Contudo, é importante ressaltar que lidar com o deploy e a implementação desses recursos pode ser uma opção mais onerosa em comparação com a utilização contínua do Amazon Fraud Detector na nossa aplicação. A escolha final dependerá das necessidades específicas do nosso projeto e das considerações de custo e benefício.\n",
        "\n",
        "**Obs.:** Criar um modelo de detecção de fraudes envolve padrões financeiros mais lógicos, os quais não teremos aqui. Mesmo que eu tenha tido o cuidado de desenvolver o script gerador de dados com uma lógica de saldo saldo atual e incremento, de acordo com a transação, criar uma lógica para detecção de fraude que necessite de um saldo anterior atualizado, saldo atual e anterior da conta credidata etc. levaria um tempo muito grande, e já levei cerca de 3 dias só para desenvolver os três scripts (gerador para o Kinesis Firehouse, função para ligação com API da função Lambda e o gerador base deste projeto, utilizado para o modelo à seguir). Assim, supondo que a solução do Amazon Fraud Detector atenderia nosso cliente em uma situação real, passarei para o desenvolvimento do modelo para solução de Marketing. Mas, para termos um overview dos dados, em relação ao setor financeiro, irei analisá-los superficialmente."
      ],
      "metadata": {
        "id": "V1u87hWOZvXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.2.1.1. Modelo Próprio - Análise de Fraude do DataSet"
      ],
      "metadata": {
        "id": "3L9RL5rkl49v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 1: Pré-processamento dos Dados\n"
      ],
      "metadata": {
        "id": "LZJHZdBHnBEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importante lembrar que cada vez que o código do gerador é iniciado, um novo arquivo dados.csv é criado. Por isso, caso o caminho seja \"data = pd.read_csv('dados.csv')\" e não de um diretório da sua máquina, **NÃO RODE ELE NOVAMENTE!!!**. Senão a base de dados vai ser modificada inteira. Como estou fazendo este estudo para entrega de um case único, irei utilizar apenas este notebook, mas não é uma boa prática pra esta situação, visto poder causar este problema mencionado. Para resolver isso, irei carregar diretamente do meu diretório drive (como já demonstrei como seria feita esta importação pelo s3, para não incorrer em gastos por consultas do s3, vou manter pelo Google Drive mesmo)\n"
      ],
      "metadata": {
        "id": "cnU9KDR4nOWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd# Carregar o arquivo CSV\n",
        "dados = pd.read_csv('/content/drive/MyDrive/Case_DadosFera/dados.csv',\n",
        "                    sep=',', encoding='iso-8859-1')\n",
        "# encoding: codificação de caracteres, normalmente utiliza-se o iso-8859-1, utf-8, latin-1)"
      ],
      "metadata": {
        "id": "ZAKKgbfTad59"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETAR A VISUALIÇÃO MÁXIMA DE COLUNAS DO DATASET\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "4AS8fFZdl2y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados.head()"
      ],
      "metadata": {
        "id": "smEUf_UPrCdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YulPj3T9rCbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHZ6uy-prCYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0GeznEzrCOI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}